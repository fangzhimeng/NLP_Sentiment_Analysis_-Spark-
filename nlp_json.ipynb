{"cells":[{"cell_type":"markdown","source":["# Sentiment Analysis of Amazon Customer Reviews"],"metadata":{}},{"cell_type":"markdown","source":["This project uses the customer review data from Amazon.com Kindle store to perform a supervised binary (positive or negative) sentiment classification analysis. We use various data pre-processing techniques and three machine learning models, namely, Naive Bayes classification model, the Logistic regression model, and the linear support vector classification model. The result provides 87% prediction accuracy."],"metadata":{}},{"cell_type":"code","source":["import pyspark\nspark.conf.set('spark.sql.shuffle.partitions', '8')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Load dataset\nThe data comes from the website \"Amazon product data\" (http://jmcauley.ucsd.edu/data/amazon/) managed by Dr. Julian McAuley from UCSD. We choose the smaller subset of the customer review data from the Kindle store of Amazon.com. The data is in the JSON format, which contains 982,619 reviews and metadata spanning May 1996 - July 2014."],"metadata":{}},{"cell_type":"code","source":["# load original .json data\nkindle_json = spark.read.json('/FileStore/tables/Kindle_Store_5.json')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["kindle_json.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n      asin|helpful|overall|          reviewText|reviewTime|    reviewerID|reviewerName|           summary|unixReviewTime|\n+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\nB000F83SZQ| [0, 0]|    5.0|I enjoy vintage b...|05 5, 2014|A1F6404F1VG29J|  Avidreader|Nice vintage story|    1399248000|\nB000F83SZQ| [2, 2]|    4.0|This book is a re...|01 6, 2014| AN0N05A9LIJEQ|    critters|      Different...|    1388966400|\nB000F83SZQ| [2, 2]|    4.0|This was a fairly...|04 4, 2014| A795DMNCJILA6|         dot|             Oldie|    1396569600|\n+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["### Generate Sentiment Label\n\nReviews with overall rating of 1, 2, or 3 are labeled as negative (label=1), and reviews with overall rating of 4 or 5 are labeled as positive (label=0)."],"metadata":{}},{"cell_type":"code","source":["kindle_json.createOrReplaceTempView('kindle_json_view')\n\ndata_json = spark.sql('''\n  SELECT CASE WHEN overall<4 THEN 1\n          ELSE 0\n          END as label,\n        reviewText as text\n  FROM kindle_json_view\n  WHERE length(reviewText)>2''')\n\ndata_json.groupBy('label').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------+\nlabel| count|\n+-----+------+\n    1|153331|\n    0|829250|\n+-----+------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["### Generate the dataset for modeling\nWe only sample a small portion of the data for demonstration and try to balance the two classes."],"metadata":{}},{"cell_type":"code","source":["# Sampling data\npos = data_json.where('label=0').sample(False, 0.05, seed=1220)\nneg = data_json.where('label=1').sample(False, 0.25, seed=1220)\ndata = pos.union(neg)\ndata.groupBy('label').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+\nlabel|count|\n+-----+-----+\n    1|38542|\n    0|41226|\n+-----+-----+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Negative reviews are on average longer than the positive reviews, but not significantly longer\nfrom pyspark.sql.functions import length\ndata.withColumn('review_length', length('text')).groupBy('label').avg('review_length').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------------+\nlabel|avg(review_length)|\n+-----+------------------+\n    1| 622.5214311660008|\n    0|  597.164071217193|\n+-----+------------------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Data Preprocessing\nData preprocessing process uses the following steps:\n\n* Use HTMLParser to un-escape the text\n* Change \"can't\" to \"can not\", and change \"n't\" to \"not\" (This is useful for the negation handling process)\n* Pad punctuations with blanks\n* Lowercase every word\n* Word tokenization\n* Word lemmatization\n* Perform **negation handling**\n    * Use a state variable to store the negation state\n    * Transform a word followed by a \"not\" or \"no\" into “not_” + word\n    * Whenever the negation state variable is set, the words read are treated as “not_” + word\n    * The state variable is reset when a punctuation mark is encountered or when there is double negation\n* Use **bigram** and/or **trigram** models"],"metadata":{}},{"cell_type":"code","source":["# Define preprocessing function\ndef clean(text):\n    import html\n    import string\n    import nltk\n    nltk.download('wordnet')\n    \n    line = html.unescape(text)\n    line = line.replace(\"can't\", 'can not')\n    line = line.replace(\"n't\", \" not\")\n    # Pad punctuations with white spaces\n    pad_punct = str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}) \n    line = line.translate(pad_punct)\n    line = line.lower()\n    line = line.split() \n    lemmatizer = nltk.WordNetLemmatizer()\n    line = [lemmatizer.lemmatize(t) for t in line] \n    \n    # Negation handling\n    # Add \"not_\" prefix to words behind \"not\", or \"no\" until the end of the sentence\n    tokens = []\n    negated = False\n    for t in line:\n        if t in ['not', 'no']:\n            negated = not negated\n        elif t in string.punctuation or not t.isalpha():\n            negated = False\n        else:\n            tokens.append('not_' + t if negated else t)\n    \n    invalidChars = str(string.punctuation.replace(\"_\", \"\"))  \n    bi_tokens = list(nltk.bigrams(line))\n    bi_tokens = list(map('_'.join, bi_tokens))\n    bi_tokens = [i for i in bi_tokens if all(j not in invalidChars for j in i)]\n    tri_tokens = list(nltk.trigrams(line))\n    tri_tokens = list(map('_'.join, tri_tokens))\n    tri_tokens = [i for i in tri_tokens if all(j not in invalidChars for j in i)]\n    tokens = tokens + bi_tokens + tri_tokens      \n    \n    return tokens"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["# An example: how the function clean() pre-processes the input text\nexample = clean(\"I don't think this book has any decent information!!! It is full of typos and factual errors that I can't ignore.\")\nprint(example)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n[&apos;i&apos;, &apos;do&apos;, &apos;not_think&apos;, &apos;not_this&apos;, &apos;not_book&apos;, &apos;not_ha&apos;, &apos;not_any&apos;, &apos;not_decent&apos;, &apos;not_information&apos;, &apos;it&apos;, &apos;is&apos;, &apos;full&apos;, &apos;of&apos;, &apos;typo&apos;, &apos;and&apos;, &apos;factual&apos;, &apos;error&apos;, &apos;that&apos;, &apos;i&apos;, &apos;can&apos;, &apos;not_ignore&apos;, &apos;i_do&apos;, &apos;do_not&apos;, &apos;not_think&apos;, &apos;think_this&apos;, &apos;this_book&apos;, &apos;book_ha&apos;, &apos;ha_any&apos;, &apos;any_decent&apos;, &apos;decent_information&apos;, &apos;it_is&apos;, &apos;is_full&apos;, &apos;full_of&apos;, &apos;of_typo&apos;, &apos;typo_and&apos;, &apos;and_factual&apos;, &apos;factual_error&apos;, &apos;error_that&apos;, &apos;that_i&apos;, &apos;i_can&apos;, &apos;can_not&apos;, &apos;not_ignore&apos;, &apos;i_do_not&apos;, &apos;do_not_think&apos;, &apos;not_think_this&apos;, &apos;think_this_book&apos;, &apos;this_book_ha&apos;, &apos;book_ha_any&apos;, &apos;ha_any_decent&apos;, &apos;any_decent_information&apos;, &apos;it_is_full&apos;, &apos;is_full_of&apos;, &apos;full_of_typo&apos;, &apos;of_typo_and&apos;, &apos;typo_and_factual&apos;, &apos;and_factual_error&apos;, &apos;factual_error_that&apos;, &apos;error_that_i&apos;, &apos;that_i_can&apos;, &apos;i_can_not&apos;, &apos;can_not_ignore&apos;]\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["# Perform data preprocessing\nfrom pyspark.sql.functions import udf, col, size\nfrom pyspark.sql.types import ArrayType, StringType\nclean_udf = udf(clean, ArrayType(StringType()))\ndata_tokens = data.withColumn('tokens', clean_udf(col('text')))\ndata_tokens.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+\nlabel|                text|              tokens|\n+-----+--------------------+--------------------+\n    0|I&apos;ve been an occa...|[i, ve, been, an,...|\n    0|There is so much ...|[there, is, so, m...|\n    0|Love this!  This ...|[love, this, this...|\n+-----+--------------------+--------------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["### Split dataset to training (70%) and testing (30%) sets"],"metadata":{}},{"cell_type":"code","source":["# Split data to 70% for training and 30% for testing\ntraining, testing = data_tokens.randomSplit([0.7,0.3], seed=1220)\ntraining.groupBy('label').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+\nlabel|count|\n+-----+-----+\n    1|26978|\n    0|28737|\n+-----+-----+\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["training.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>DataFrame[label: int, text: string, tokens: array&lt;string&gt;]\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["### Naive Bayes Model (with parameter tuning)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer, IDF\nfrom pyspark.ml import Pipeline\n\ncount_vec = CountVectorizer(inputCol='tokens', outputCol='c_vec', minDF=5.0)\nidf = IDF(inputCol=\"c_vec\", outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["# Naive Bayes model\nfrom pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes()\n\npipeline_nb = Pipeline(stages=[count_vec, idf, nb])\n\nmodel_nb = pipeline_nb.fit(training)\ntest_nb = model_nb.transform(testing)\ntest_nb.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nlabel|                text|              tokens|               c_vec|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n    0|&quot;A Calm Whisper&quot;:...|[a, calm, whisper...|(237599,[0,1,2,3,...|(237599,[0,1,2,3,...|[-35891.606184157...|           [1.0,0.0]|       0.0|\n    0|&quot;A Work in Progre...|[a, work, in, pro...|(237599,[0,1,2,3,...|(237599,[0,1,2,3,...|[-11666.318940416...|[1.0,2.1104994083...|       0.0|\n    0|&quot;It&apos;s impossible ...|[it, s, impossibl...|(237599,[0,1,2,3,...|(237599,[0,1,2,3,...|[-11361.684192180...|[1.0,2.1713068771...|       0.0|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["#### Naive Bayes model performance (using default parameters)\n* Area under the ROC curve: 0.8551\n* Accuracy: 0.8553"],"metadata":{}},{"cell_type":"code","source":["# Naive Bayes model ROC\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nroc_nb_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\nroc_nb = roc_nb_eval.evaluate(test_nb)\nprint(\"ROC of the NB model: {}\".format(roc_nb))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ROC of the NB model: 0.8550587747934197\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["# Naive Bayes model accuracy\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_nb_eval = MulticlassClassificationEvaluator(metricName='accuracy')\nacc_nb = acc_nb_eval.evaluate(test_nb)\nprint(\"Accuracy of the NB model: {}\".format(acc_nb))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of the NB model: 0.8552779279092005\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["#### Naive Bayes model performance after parameter tuning\n* CountVectorizer.minDF = 7.0\n* NaiveBayes.smooting = 1.0\n* Accuracy: 0.8568 (increased from 0.8553)"],"metadata":{}},{"cell_type":"code","source":["# NB parameter tuning and CV\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid_nb = (ParamGridBuilder()\n                .addGrid(count_vec.minDF, [3.0, 5.0, 7.0, 10.0, 15.0])\n                .addGrid(nb.smoothing, [0.1, 0.5, 1.0])\n                .build())\ncv_nb = CrossValidator(estimator=pipeline_nb, estimatorParamMaps=paramGrid_nb, evaluator=acc_nb_eval, numFolds=5)\ncv_model_nb = cv_nb.fit(training) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["test_cv_nb = cv_model_nb.transform(testing)\nacc_nb_cv = acc_nb_eval.evaluate(test_cv_nb)\nprint(\"Accuracy of the NB CV model: {}\".format(acc_nb_cv))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of the NB CV model: 0.8568161975637134\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["cv_model_nb.bestModel.stages[0].extractParamMap()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">44</span><span class=\"ansired\">]: </span>\n{Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;inputCol&apos;, doc=&apos;input column name&apos;): &apos;tokens&apos;,\n Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;binary&apos;, doc=&apos;If True, all non zero counts are set to 1.&apos;): False,\n Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;vocabSize&apos;, doc=&apos;max size of the vocabulary&apos;): 262144,\n Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;minDF&apos;, doc=&apos;Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer &gt;= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents.&apos;): 7.0,\n Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;outputCol&apos;, doc=&apos;output column name&apos;): &apos;c_vec&apos;,\n Param(parent=&apos;CountVectorizer_44cda3f9b64132bd062e&apos;, name=&apos;minTF&apos;, doc=&quot;Filter to ignore rare words in a document. For each document, terms with frequency/count less than the given threshold are ignored. If this is an integer &gt;= 1, then this specifies a count (of times the term must appear in the document); if this is a double in [0,1), then this specifies a fraction (out of the document&apos;s token count). Note that the parameter is only used in transform of CountVectorizerModel and does not affect fitting.&quot;): 1.0}\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["cv_model_nb.bestModel.stages[2].extractParamMap()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>\n{Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;predictionCol&apos;, doc=&apos;prediction column name&apos;): &apos;prediction&apos;,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;rawPredictionCol&apos;, doc=&apos;raw prediction (a.k.a. confidence) column name&apos;): &apos;rawPrediction&apos;,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;probabilityCol&apos;, doc=&apos;Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities&apos;): &apos;probability&apos;,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;modelType&apos;, doc=&apos;The model type which is a string (case-sensitive). Supported options: multinomial (default) and bernoulli.&apos;): &apos;multinomial&apos;,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;smoothing&apos;, doc=&apos;The smoothing parameter.&apos;): 1.0,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;labelCol&apos;, doc=&apos;label column name&apos;): &apos;label&apos;,\n Param(parent=&apos;NaiveBayes_43c0b7665b211d226a53&apos;, name=&apos;featuresCol&apos;, doc=&apos;features column name&apos;): &apos;features&apos;}\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["### Logistic Regressions\nModel performance (using default parameters)\n* Area under the ROC curve: 0.8601\n* Accuracy: 0.8610"],"metadata":{}},{"cell_type":"code","source":["# Logistic Regression model\nfrom pyspark.ml.classification import LogisticRegression\nlgr = LogisticRegression(maxIter=5)\npipeline_lgr = Pipeline(stages=[count_vec, idf, lgr])\n\nmodel_lgr = pipeline_lgr.fit(training)\ntest_lgr = model_lgr.transform(testing)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["# Logistic Regression model ROC\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nroc_lgr_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\nroc_lgr = roc_lgr_eval.evaluate(test_lgr)\nprint(\"ROC of the model: {}\".format(roc_lgr))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ROC of the model: 0.8601176818374295\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["# Logistic Regression model accuracy\n#from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_lgr_eval = MulticlassClassificationEvaluator(metricName='accuracy')\nacc_lgr = acc_lgr_eval.evaluate(test_lgr)\nprint(\"Accuracy of the model: {}\".format(acc_lgr))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of the model: 0.8609736831164512\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["### Linear SVC Model\nModel performance (using default parameters)\n* Area under the ROC curve: 0.8649\n* Accuracy: 0.8656"],"metadata":{}},{"cell_type":"code","source":["# Linear SVC model\nfrom pyspark.ml.classification import LinearSVC\nlsvc = LinearSVC(maxIter=5)\npipeline_lsvc = Pipeline(stages=[count_vec, idf, lsvc])\n\nmodel_lsvc = pipeline_lsvc.fit(training)\ntest_lsvc = model_lsvc.transform(testing)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["# Linear SVC model ROC\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nroc_lsvc_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\nroc_lsvc = roc_lsvc_eval.evaluate(test_lsvc)\nprint(\"ROC of the model: {}\".format(roc_lsvc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ROC of the model: 0.8648930463858352\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["# Linear SVC model accuracy\n#from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_lsvc_eval = MulticlassClassificationEvaluator(metricName='accuracy')\nacc_lsvc = acc_lsvc_eval.evaluate(test_lsvc)\nprint(\"Accuracy of the model: {}\".format(acc_lsvc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of the model: 0.8656300669355174\n</div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["### Predict on new reviews:\nTo demonstrate the model prediction on new review texts, I randomly choose five reviews from the Kindle book *The Brave Ones: A Memoir of Hope, Pride and Military Service, by Michael J. MacLeod*. \n\nThe suffixes \"_1\", \"_2\", ..., \"_5\" indicate the real overall review stars 1, 2, ..., 5.\n\nThe model correctly predicts the first three reviews as \"negative\" (label=1), and the last two as \"positive\" (label=0)."],"metadata":{}},{"cell_type":"code","source":["review_1 = [\"WOW!!! No words describe how bland this book is. It took me a lot to even pick up to read. I would definitely not recommend this book.\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["review_2 = [\"A first person account of the war in Afghanistan. It skipps around a lot and is like a never-ending news article. On the positive side, you do get a feel for what desert fighting is like from a soldiers point of view.\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":40},{"cell_type":"code","source":["review_3 = [\"I liked the premise and most of the book. At the end parts I lost a little interest because I lost the thread of who was who. War is hell. MacLeod did his service unlike most of us.\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["review_4 = [\"Very informative first person account of the the daily life of a US Paratrooper. From training to deployment in combat situations in Afghanistan. Well worth the read and makes you really understand and appreciate their sacrifices\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["review_5 = [\"This is perhaps the best wrote book I have ever read. Articulate and thought provoking. Not just a riveting account of actual combat, but Michael was able to do what few before him have...captured the essence of what one feels as the battle unfolds. Perhaps most of all, I am grateful to call this author 'Fellow Warrior' Airborne all the way!!!\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["from pyspark.sql.types import *\nschema = StructType([StructField(\"text\", StringType(), True)])\n\ntext = [review_1, review_2, review_3, review_4, review_5]\nreview_new = spark.createDataFrame(text, schema=schema)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["# Data preprocessing\nreview_new_tokens = review_new.withColumn('tokens', clean_udf(col('text')))\nreview_new_tokens.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+\n                text|              tokens|\n+--------------------+--------------------+\nWOW!!! No words d...|[wow, not_word, n...|\nA first person ac...|[a, first, person...|\nI liked the premi...|[i, liked, the, p...|\nVery informative ...|[very, informativ...|\nThis is perhaps t...|[this, is, perhap...|\n+--------------------+--------------------+\n\n</div>"]}}],"execution_count":45},{"cell_type":"code","source":["# Prediction using tuned Naive Bayes model\nresult = cv_model_nb.transform(review_new_tokens)\nresult.select('text', 'prediction').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------+\n                text|prediction|\n+--------------------+----------+\nWOW!!! No words d...|       1.0|\nA first person ac...|       1.0|\nI liked the premi...|       1.0|\nVery informative ...|       0.0|\nThis is perhaps t...|       0.0|\n+--------------------+----------+\n\n</div>"]}}],"execution_count":46},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47}],"metadata":{"name":"nlp_json","notebookId":190787089418947},"nbformat":4,"nbformat_minor":0}
